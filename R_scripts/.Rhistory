True_score.mult = True_score.mult,
age_values_o =  train.demo.data$age_values_o,
edu_values_o = train.demo.data$edu_values_o,
sex_values_o = train.demo.data$sex_values_o,
age_transf = train.age_transf,
edu_transf = train.edu_transf
)
train.dat = train.res[[1]]
TRAIN_GT_TRANSF[iS]=train.res[[2]]
if (F){
par(mfrow=c(1,2))
plot(train.dat$Age, train.dat$Obs_score)
plot(train.dat$Edu, train.dat$Obs_score)
}
#
range(train.dat$Obs_score)
TRAIN_GT_SCORE_RANGE[[iS]]=range(train.dat$Demo_score) # to check actual range
#  1a) calculate ground truth below cut-off obs
TRAIN_ADJ.GT= train.dat$P_score
TRAIN_ES.GT = ES(adjscores= train.dat$P_score)$Adjusted_Scores
TRAIN_Below.GT = train.dat$P_score<TRAIN_ES.GT[1]
#
TRAIN_GT_RS[iS] = 1 - sum(train.dat$P_score^2)/sum((train.dat$Obs_score-mean(train.dat$Obs_score))^2)
#### INITIALIZE PERFORMANCE OF METHODS
# USE GT FOR BUILDING A NULL DISTRIBUTION
# 2) compute adj score with Capitani method
CAP.res = adjscores_C1987(df=train.dat, dep="Obs_score",
age="Age", edu="Edu", sex="Sex",
dep.range = c(0, max(train.dat$Obs_score))
)
dat.adj.CAP = CAP.res$new.df
TRAIN_CAP_TRANSF[[iS]] = CAP.res$transfs
TRAIN_CAP_RS[iS]=summary(CAP.res$lm.model)$r.squared
TRAIN_CAP_FORMULA[[iS]]=formula(CAP.res$lm.model)
# 2a) calculate Capitani's below cut-off obs
TRAIN_ADJ.CAP = dat.adj.CAP$RESIDUALS
TRAIN_ES.CAP = ES(adjscores= dat.adj.CAP$RESIDUALS)$Adjusted_Scores
TRAIN_Below.CAP = dat.adj.CAP$RESIDUALS<TRAIN_ES.CAP[1]
# 3) compute adj score with Arcara's method
# 3a) compute Arcara's below-cut-off obs
ARC.res = adjscores_A2022_v3a(df = train.dat, dep="Obs_score",
age="Age", edu="Edu", sex="Sex_n",
dep.range = c(0, max(train.dat$Obs_score)),
#k=4,
NULL)
dat.adj.ARC = ARC.res$new.df
TRAIN_ARC_TRANSF[[iS]] = ARC.res$transfs
TRAIN_ARC_RS[iS]=summary(ARC.res$lm.model)$r.sq
TRAIN_ARC_FORMULA[[iS]]=formula(ARC.res$lm.model)
# 2a) calculate Capitani's below cut-off obs
TRAIN_ADJ.ARC = dat.adj.ARC$RESIDUALS
TRAIN_ES.ARC = ES(adjscores= dat.adj.ARC$RESIDUALS)$Adjusted_Scores
TRAIN_Below.ARC = dat.adj.ARC$RESIDUALS<TRAIN_ES.ARC[1]
# COMPUTE ERRORS
# RESID ERR (mean squared error)
TRAIN_CAP_RESID_ERR[iS] = mean((TRAIN_ADJ.CAP-TRAIN_ADJ.GT)^2)
TRAIN_ARC_RESID_ERR[iS] = mean((TRAIN_ADJ.ARC-TRAIN_ADJ.GT)^2)
TRAIN_GT_BEL[iS] = sum(TRAIN_Below.GT)
# CLASS_ERR_BEL, proportion of classifications of below made from the GT are NOT below according to the method.
TRAIN_CAP_CLASS_ERR_BEL[iS] = length(setdiff(which(TRAIN_Below.GT), which(TRAIN_Below.CAP))) / length(which(TRAIN_Below.GT)) # error
TRAIN_ARC_CLASS_ERR_BEL[iS] = length(setdiff(which(TRAIN_Below.GT), which(TRAIN_Below.ARC))) / length(which(TRAIN_Below.GT)) # error
# CLASS_ERR_ABO, how many classifications of equal/above made from the GT are NOT equal/above according to the method.
TRAIN_CAP_CLASS_ERR_ABO[iS] = length(setdiff(which(!TRAIN_Below.GT), which(!TRAIN_Below.CAP))) / length(which(!TRAIN_Below.GT)) # error
TRAIN_ARC_CLASS_ERR_ABO[iS] = length(setdiff(which(!TRAIN_Below.GT), which(!TRAIN_Below.ARC))) / length(which(!TRAIN_Below.GT)) # error
progress_bar(iS, n.sim, 10)
test.demo.data = sample.demo.unif(n.subj.test)
test.res = sim.norm.data(n = n.subj.test,
coefs = train.coefs,
True_score.mult = True_score.mult,
age_values_o =  test.demo.data$age_values_o,
edu_values_o = test.demo.data$edu_values_o,
sex_values_o = test.demo.data$sex_values_o,
age_transf = train.age_transf,
edu_transf = train.edu_transf
)
test.dat = test.res[[1]]
TEST.Below.GT = test.dat$P_score<TRAIN_ES.GT[1]
SUM_TEST.Below.GT[iS] = sum(test.dat$P_score<TRAIN_ES.GT[1])
### ADD CAPITANI AND ARCARA METHOD HERE TO CHECK PERFORMANCE ON "NEW TEST SET".
CAP.test_resid = test.dat$Obs_score - predict(CAP.res$lm.model,
newdata = list(age_tr=eval(parse(file="", text=paste(CAP.res$transfs[[1]], "(test.dat$Age)", sep=""))),
edu_tr=eval(parse(file="", text=paste(CAP.res$transfs[[2]], "(test.dat$Edu)", sep=""))),
sex=test.dat$Sex))
ARC.test_resid = test.dat$Obs_score - predict(ARC.res$lm.model,
newdata = list(age_tr=eval(parse(file="", text=paste(ARC.res$transfs[[1]], "(test.dat$Age)", sep=""))),
edu_tr=eval(parse(file="", text=paste(ARC.res$transfs[[2]], "(test.dat$Edu)", sep=""))),
sex=test.dat$Sex_n))
TEST_CAP_RESID_ERR[iS] = mean((CAP.test_resid - test.dat$P_score)^2)
TEST_ARC_RESID_ERR[iS] = mean((ARC.test_resid - test.dat$P_score)^2)
# maybe here you can add a check of performance for test set similar to the train set.
TEST.Below.CAP = CAP.test_resid<TRAIN_ES.CAP[1]
TEST.Below.ARC = ARC.test_resid<TRAIN_ES.ARC[1]
SUM_TEST.Below.CAP[iS] = sum(CAP.test_resid<TRAIN_ES.CAP[1])
SUM_TEST.Below.ARC[iS] = sum(ARC.test_resid<TRAIN_ES.ARC[1])
# CLASS_ERR_BEL, proportion of classifications of below made from the GT are NOT below according to the method.
TEST_CAP_CLASS_ERR_BEL[iS] = length(setdiff(which(TEST.Below.GT), which(TEST.Below.CAP))) / length(which(TEST.Below.GT)) # error
TEST_ARC_CLASS_ERR_BEL[iS] = length(setdiff(which(TEST.Below.GT), which(TEST.Below.ARC))) / length(which(TEST.Below.GT)) # error
# CLASS_ERR_ABO, how many classifications of equal/above made from the GT are NOT equal/above according to the method.
TEST_CAP_CLASS_ERR_ABO[iS] = length(setdiff(which(!TEST.Below.GT), which(!TEST.Below.CAP))) / length(which(!TEST.Below.GT)) # error
TEST_ARC_CLASS_ERR_ABO[iS] = length(setdiff(which(!TEST.Below.GT), which(!TEST.Below.ARC))) / length(which(!TEST.Below.GT)) # error
}
EXPECTED_BELOW =  TRAIN_GT_BEL[1] # I use the first elements cause they are all the same
# (and dependent) on the N
save(TRAIN_ARC_RS, TRAIN_CAP_RS, TRAIN_GT_RS,
TRAIN_CAP_FORMULA, TRAIN_ARC_FORMULA,
TRAIN_CAP_RESID_ERR, TRAIN_ARC_RESID_ERR,
TRAIN_CAP_CLASS_ERR_BEL, TRAIN_ARC_CLASS_ERR_BEL,
TRAIN_CAP_CLASS_ERR_ABO, TRAIN_ARC_CLASS_ERR_ABO,
TEST.Below.GT, TEST.Below.CAP, TEST.Below.ARC,
TEST_CAP_CLASS_ERR_BEL, TEST_ARC_CLASS_ERR_BEL,
TEST_CAP_CLASS_ERR_ABO, TEST_ARC_CLASS_ERR_ABO,
file=paste("Results/Sim", Sys.time(), ".RData", sep=""))
rm(list=ls())
source("R_functions/adjscores_C1987.R")
source("R_functions/adjscores_A2022_v1.R")
source("R_functions/adjscores_A2022_v2.R")
source("R_functions/adjscores_A2022_v3.R")
source("R_functions/adjscores_A2022_v3a.R")
source("R_functions/adjscores_A2022_v4.R")
source("R_functions/adjscores_A2022_v5.R")
source("R_functions/adjscores_A2022_v6.R")
source("R_functions/adjscores_A2022_v7.R")
TRAIN_CAP_RESID_ERR = NULL
TRAIN_ARC_RESID_ERR = NULL
## calculate error in classification BELOW
TRAIN_CAP_CLASS_ERR_BEL = NULL
TRAIN_ARC_CLASS_ERR_BEL = NULL
TRAIN_CAP_CLASS_ERR_ABO = NULL
rm(list=ls())
source("R_functions/adjscores_C1987.R")
source("R_functions/adjscores_A2023_v1.R")
source("R_functions/adjscores_A2023_v2.R")
source("R_functions/adjscores_A2023_v2a.R")
source("R_functions/adjscores_A2023_v3.R")
source("R_functions/sim.norm.data.R")
source("R_functions/lm.drop.F.R")
source("R_functions/ES.R")
source("R_functions/tolLimits.obs.R")
source("R_functions/progress_bar.R")
source("R_functions/sample.demo.unif.R")
source("R_functions/sample.coef.unif.R")
source("R_functions/sample.transf.R")
source("R_functions/transf_functions.R")
source("R_functions/model_text.R")
source("R_functions/model_text_transf.R")
#################################
## SET SIMULATION PARAMETERS ####
#################################
n.sim = 1000 # number of simulations
n.subj.train = 70 # number of subjects in each train set (i.e., the normative data)
n.subj.test = 400 # number of subjects in each test set (i.e., the participant/patients tested)
True_score.mult = 3 # a multiplier to have an effect of noise (in terms of error), not influenced by the observed score range in the simulation.
#  this choice, warrant a R^2 in the models not depending by the transformations used (e.g., with cubic transf, it could change a lot)
## coefficients parameters
c.range = list(c(10, 12), c(-0.05, -0.1), c(0.05, 0.1), c(-0.01, 0.01), c(-0.005, -0.001), c(0.001, 0.005))
c.steps = c(100,100,100,100,100, 100)
eff_mult = c(1, 1, 1, 0.5, 1, 1)
age.include.transf = NULL
age.exclude.transf = c("poly2") #c("quadr", "cube")
edu.include.transf = NULL
edu.exclude.transf = c("poly2") #c("quadr", "cube")
adjscores_A2023 = adjscores_A2023_v2a
sim.params = list(n.sim = n.sim, n.subj.train=n.subj.train, n.subj.test = n.subj.test, True_score.mult = True_score.mult, c.range = c.range, c.steps = c.steps, transf=list(age.include.transf = age.include.transf, age.exclude.transf=age.exclude.transf, edu.include.transf=edu.include.transf, edu.exclude.transf=edu.exclude.transf))
#################################
#################################
#### INITIALIZE OUTPUT OBJECTS
#################################
#################################
# note
# object with all CAPITAL letters denotes objects that collect results of the simulation
# (i.e., typically one dimension is equal to n.sim)
# objects with Sentence case (only first word is capital), denote objects created for that specific iS of the simulation
#################################
# ### TRAIN SET PERFORMANCE
TRAIN_GT_RESID = NULL
TRAIN_CAP_RESID_ERR = NULL
TRAIN_ARC_RESID_ERR = NULL
## calculate error in classification BELOW (discrepancy between method and ground truth)
TRAIN_CAP_CLASS_ERR_BEL = NULL
TRAIN_ARC_CLASS_ERR_BEL = NULL
TRAIN_CAP_CLASS_ERR_ABO = NULL
TRAIN_ARC_CLASS_ERR_ABO = NULL
TRAIN_GT_BEL_SUM = NULL
TRAIN_CAP_BEL_SUM = NULL
TRAIN_ARC_BEL_SUM = NULL
## OTHER OBJECTS FOR PERFOMANCE EVALUATIONS
# create list of transformation, as identified by the method.
TRAIN_GT_TRANSF = list(NULL)
length(TRAIN_GT_TRANSF)=n.sim
TRAIN_CAP_TRANSF = list(NULL)
length(TRAIN_CAP_TRANSF)=n.sim
TRAIN_ARC_TRANSF = list(NULL)
length(TRAIN_ARC_TRANSF)=n.sim
TRAIN_CAP_RS = NULL
TRAIN_ARC_RS = NULL
TRAIN_GT_RS = NULL
TRAIN_GT_MODEL_TEXT = NULL
TRAIN_CAP_MODEL_TEXT = NULL
TRAIN_ARC_MODEL_TEXT = NULL
# object containing the formula of the models
TRAIN_CAP_FORMULA = list(NULL)
length(TRAIN_CAP_FORMULA)=n.sim
TRAIN_ARC_FORMULA = list(NULL)
length(TRAIN_ARC_FORMULA)=n.sim
TRAIN_GT_SCORE_RANGE = list(NULL)
length(TRAIN_GT_SCORE_RANGE)=n.sim
#################################
## TEST SET PERFORMANCE
# initialize objects for test set
TEST_GT_BELOW = NULL
TEST_CAP_BELOW = NULL
TEST_ARC_BELOW = NULL
TEST_GT_BELOW_SUM = NULL
TEST_CAP_BELOW_SUM = NULL
TEST_ARC_BELOW_SUM = NULL
TEST_CAP_RESID_ERR = NULL
TEST_ARC_RESID_ERR = NULL
TEST_CAP_CLASS_ERR_BEL=NULL
TEST_ARC_CLASS_ERR_BEL=NULL
TEST_CAP_CLASS_ERR_ABO=NULL
TEST_ARC_CLASS_ERR_ABO=NULL
#iS=1
for (iS in 1:n.sim){
## 1) simulate data with real adj score
train.demo.data = sample.demo.unif(n.subj.train)
train.coefs = sample.coef.unif(c.range = c.range,
c.steps=c.steps)
train.age_transf = sample.transf(include_transf = age.include.transf, exclude_transf = age.exclude.transf)
train.edu_transf = sample.transf(include_transf = edu.include.transf, exclude_transf = edu.exclude.transf)
train.res = sim.norm.data_v2(n = n.subj.train,
coefs = train.coefs,
True_score.mult = True_score.mult,
eff_mult = eff_mult,
age_values_o =  train.demo.data$age_values_o,
edu_values_o = train.demo.data$edu_values_o,
sex_values_o = train.demo.data$sex_values_o,
age_transf = train.age_transf,
edu_transf = train.edu_transf
)
train.dat = train.res[[1]]
TRAIN_GT_MODEL_TEXT[[iS]]=train.res[[2]]
# small plots for check
if (F){
par(mfrow=c(1,2))
plot(train.dat$Age, train.dat$Obs_score)
plot(train.dat$Edu, train.dat$Obs_score)
}
#
range(train.dat$Obs_score)
TRAIN_GT_SCORE_RANGE[[iS]]=range(train.dat$Demo_score) # to check actual range, for debugging and checks
TRAIN_GT_TRANSF[[iS]] = c(train.age_transf, train.edu_transf)
#  1a) calculate ground truth below cut-off obs
Train_Adj.GT= train.dat$P_score
Train_ES.GT = ES(adjscores= train.dat$P_score)$Adjusted_Scores
Train_Below.GT = train.dat$P_score<=Train_ES.GT[1]
#  calculate R squadred for the Ground Truth.
TRAIN_GT_RS[iS] = 1 - sum(train.dat$P_score^2)/sum((train.dat$Obs_score-mean(train.dat$Obs_score))^2)
TRAIN_GT_RESID[iS] = mean(Train_Adj.GT) # this is just for check: it is expected to be = 0.
#### INITIALIZE PERFORMANCE OF METHODS
# USE GT FOR BUILDING A NULL DISTRIBUTION
# 2) compute adj score with Capitani method
CAP.res = adjscores_C1987(df=train.dat, dep="Obs_score",
age="Age", edu="Edu", sex="Sex",
dep.range = c(0, max(train.dat$Obs_score))
)
dat.adj.CAP = CAP.res$new.df
TRAIN_CAP_TRANSF[[iS]] = CAP.res$transfs
TRAIN_CAP_RS[iS]=summary(CAP.res$lm.model)$r.squared
TRAIN_CAP_FORMULA[[iS]]=formula(CAP.res$lm.model)
TRAIN_CAP_MODEL_TEXT[iS]=CAP.res$model_text
# 2a) calculate Capitani's below cut-off obs
Train_Adj.CAP = dat.adj.CAP$RESIDUALS
Train_ES.CAP = ES(adjscores= dat.adj.CAP$RESIDUALS)$Adjusted_Scores
Train_Below.CAP = dat.adj.CAP$RESIDUALS<=Train_ES.CAP[1]
# 3) compute adj score with Arcara's method
# 3a) compute Arcara's below-cut-off obs
ARC.res = adjscores_A2023(df = train.dat, dep="Obs_score",
age="Age", edu="Edu", sex="Sex_n",
dep.range = c(0, max(train.dat$Obs_score)),
#k=4,
NULL)
dat.adj.ARC = ARC.res$new.df
TRAIN_ARC_TRANSF[[iS]] = ARC.res$transfs
TRAIN_ARC_RS[iS]=summary(ARC.res$lm.model)$r.sq
TRAIN_ARC_FORMULA[[iS]]=formula(ARC.res$lm.model)
TRAIN_ARC_MODEL_TEXT[iS]=ARC.res$model_text
# 2a) calculate Arcara's below cut-off obs
Train_Adj.ARC = dat.adj.ARC$RESIDUALS
Train_ES.ARC = ES(adjscores= dat.adj.ARC$RESIDUALS)$Adjusted_Scores
Train_Below.ARC = dat.adj.ARC$RESIDUALS<=Train_ES.ARC[1]
###########################
# COMPUTE TRAIN SET ERRORS
# RESID ERR (mean squared error)
TRAIN_CAP_RESID_ERR[iS] = mean((Train_Adj.CAP-Train_Adj.GT)^2)
TRAIN_ARC_RESID_ERR[iS] = mean((Train_Adj.ARC-Train_Adj.GT)^2)
TRAIN_GT_BEL_SUM[iS] = sum(Train_Below.GT) #
TRAIN_CAP_BEL_SUM[iS] = sum(Train_Below.CAP)
TRAIN_ARC_BEL_SUM[iS] = sum(Train_Below.ARC)
# CLASS_ERR_BEL, proportion of classifications of below made from the GT are NOT below according to the method.
TRAIN_CAP_CLASS_ERR_BEL[iS] = length(setdiff(which(Train_Below.GT), which(Train_Below.CAP))) / length(which(Train_Below.GT)) # error
TRAIN_ARC_CLASS_ERR_BEL[iS] = length(setdiff(which(Train_Below.GT), which(Train_Below.ARC))) / length(which(Train_Below.GT)) # error
# CLASS_ERR_ABO, how many classifications of equal/above made from the GT are NOT equal/above according to the method.
TRAIN_CAP_CLASS_ERR_ABO[iS] = length(setdiff(which(!Train_Below.GT), which(!Train_Below.CAP))) / length(which(!Train_Below.GT)) # error
TRAIN_ARC_CLASS_ERR_ABO[iS] = length(setdiff(which(!Train_Below.GT), which(!Train_Below.ARC))) / length(which(!Train_Below.GT)) # error
progress_bar(iS, n.sim, 10)
test.demo.data = sample.demo.unif(n.subj.test)
test.res = sim.norm.data(n = n.subj.test,
coefs = train.coefs,
True_score.mult = True_score.mult,
eff_mult = eff_mult,
age_values_o =  test.demo.data$age_values_o,
edu_values_o = test.demo.data$edu_values_o,
sex_values_o = test.demo.data$sex_values_o,
age_transf = train.age_transf,
edu_transf = train.edu_transf
)
test.dat = test.res[[1]]
TEST_GT_BELOW = test.dat$P_score<=Train_ES.GT[1]
TEST_GT_BELOW_SUM[iS] = sum(test.dat$P_score<=Train_ES.GT[1])
### ADD CAPITANI AND ARCARA METHOD HERE TO CHECK PERFORMANCE ON "NEW TEST SET".
CAP.test_resid = test.dat$Obs_score - predict(CAP.res$lm.model,
newdata = list(age_tr=eval(parse(file="", text=paste(CAP.res$transfs[[1]], "(test.dat$Age)", sep=""))),
edu_tr=eval(parse(file="", text=paste(CAP.res$transfs[[2]], "(test.dat$Edu)", sep=""))),
sex=test.dat$Sex))
ARC.test_resid = test.dat$Obs_score - predict(ARC.res$lm.model,
newdata = list(age_tr=eval(parse(file="", text=paste(ARC.res$transfs[[1]], "(test.dat$Age)", sep=""))),
edu_tr=eval(parse(file="", text=paste(ARC.res$transfs[[2]], "(test.dat$Edu)", sep=""))),
sex=test.dat$Sex_n))
TEST_CAP_RESID_ERR[iS] = mean((CAP.test_resid - test.dat$P_score)^2)
TEST_ARC_RESID_ERR[iS] = mean((ARC.test_resid - test.dat$P_score)^2)
# maybe here you can add a check of performance for test set similar to the train set.
TEST_CAP_BELOW = CAP.test_resid<=Train_ES.CAP[1]
TEST_ARC_BELOW = ARC.test_resid<=Train_ES.ARC[1]
TEST_CAP_BELOW_SUM[iS] = sum(CAP.test_resid<=Train_ES.CAP[1])
TEST_ARC_BELOW_SUM[iS] = sum(ARC.test_resid<=Train_ES.ARC[1])
# CLASS_ERR_BEL, proportion of classifications of below made from the GT are NOT below according to the method.
TEST_CAP_CLASS_ERR_BEL[iS] = length(setdiff(which(TEST_GT_BELOW), which(TEST_CAP_BELOW))) / length(which(TEST_GT_BELOW)) # error
TEST_ARC_CLASS_ERR_BEL[iS] = length(setdiff(which(TEST_GT_BELOW), which(TEST_ARC_BELOW))) / length(which(TEST_GT_BELOW)) # error
# CLASS_ERR_ABO, how many classifications of equal/above made from the GT are NOT equal/above according to the method.
TEST_CAP_CLASS_ERR_ABO[iS] = length(setdiff(which(!TEST_GT_BELOW), which(!TEST_CAP_BELOW))) / length(which(!TEST_GT_BELOW)) # error
TEST_ARC_CLASS_ERR_ABO[iS] = length(setdiff(which(!TEST_GT_BELOW), which(!TEST_ARC_BELOW))) / length(which(!TEST_GT_BELOW)) # error
}  # for iSim
EXPECTED_BELOW =  TRAIN_GT_BEL_SUM[1] # I use the first elements cause they are all the same
# (and dependent) on the N
#  full results save
save(sim.params, adjscores_A2023,
TRAIN_ARC_RS, TRAIN_CAP_RS, TRAIN_GT_RS,
TRAIN_CAP_FORMULA, TRAIN_ARC_FORMULA,
TRAIN_CAP_RESID_ERR, TRAIN_ARC_RESID_ERR, TRAIN_GT_RESID,
TRAIN_CAP_CLASS_ERR_BEL, TRAIN_ARC_CLASS_ERR_BEL,
TRAIN_CAP_CLASS_ERR_ABO, TRAIN_ARC_CLASS_ERR_ABO,
TRAIN_CAP_TRANSF, TRAIN_ARC_TRANSF,
TRAIN_GT_MODEL_TEXT, TRAIN_CAP_MODEL_TEXT, TRAIN_ARC_MODEL_TEXT,
TEST_GT_BELOW, TEST_CAP_BELOW, TEST_ARC_BELOW,
TEST_CAP_CLASS_ERR_BEL, TEST_ARC_CLASS_ERR_BEL,
TEST_CAP_CLASS_ERR_ABO, TEST_ARC_CLASS_ERR_ABO,
file=paste("Results/Sim_Nsize_", n.subj.train, "_Noise_", True_score.mult,".RData", sep=""))
rm(list=ls())
source("R_functions/adjscores_C1987.R")
source("R_functions/adjscores_A2023_v1.R")
source("R_functions/adjscores_A2023_v2.R")
source("R_functions/adjscores_A2023_v2a.R")
source("R_functions/adjscores_A2023_v3.R")
source("R_functions/sim.norm.data.R")
source("R_functions/lm.drop.F.R")
source("R_functions/ES.R")
source("R_functions/tolLimits.obs.R")
source("R_functions/progress_bar.R")
source("R_functions/sample.demo.unif.R")
source("R_functions/sample.coef.unif.R")
source("R_functions/sample.transf.R")
source("R_functions/transf_functions.R")
source("R_functions/model_text.R")
source("R_functions/model_text_transf.R")
#################################
## SET SIMULATION PARAMETERS ####
#################################
n.sim = 1000 # number of simulations
n.subj.train = 70 # number of subjects in each train set (i.e., the normative data)
n.subj.test = 400 # number of subjects in each test set (i.e., the participant/patients tested)
True_score.mult = 3 # a multiplier to have an effect of noise (in terms of error), not influenced by the observed score range in the simulation.
#  this choice, warrant a R^2 in the models not depending by the transformations used (e.g., with cubic transf, it could change a lot)
dir()
## a function to sample from some transformations
# it could be used to define randomly the relationship between a predictor (e.g. age) and a score.
# the list of function used is
# include_transf = the transformations to be included in the sampling. If NULL all transformation in the list are used.
#  (See within the function for the list)
# exclude_transf = the transformations to be included in the sampling. IF NULL no transformation is excluded.
sample.transf = function(include_transf= NULL, exclude_transf=NULL){
#compute most common transformations for age and education
cube = function(x){x^3}
quadr = function(x){x^2}
logm100 = function(x){log(100-x)}
log10m100 = function(x){log10(100-x)}
log10mAve = function(x){log10(100-mean(x))}
inv = function(x){1/x}
poly2 = function(x){poly(x,2)}
# sqrt
# log
# you can add new functions here, creating them if necessary
if(is.null(include_transf)){
transf_list = c("identity",  "quadr", "log10", "logm100", "log", "log10m100", "inv", "sqrt", "poly2", "cube", "zero") #"cube","log10mAve",
} else {
transf_list = include_transf
}
transf_list=setdiff(transf_list, exclude_transf)
curr_transf = sample(transf_list, 1)
return(curr_transf)
}
rm(list=ls())
sample_size = 100
Noise_level = 3
Arcara_ver = "v5"
Capitani_ver = "v2"
sample_demo_fun = "sample.demo.cond"
tag=""
curr_file = paste("Results/Sim_Nsize_", sample_size, "_Noise_", Noise_level, "_A", Arcara_ver, "_C", Capitani_ver, "_", sample_demo_fun, tag, ".RData", sep="")
load(curr_file)
file_name = paste("Results/Sim_Nsize_", n.subj.train, "_Noise_", True_score.mult,"_A", Arcara_ver, "_C", Capitani_ver, "_", sample_demo_fun, tag, ".RData", sep="")
loop_list
loop_list
### MAIN SCRIPT
# this script regulates the main values used for the simulation the article
# Arcara G. (2023) Improving ES.
rm(list=ls())
# the possible values of number of subjects on which normative data are built
sample_size_values = c(100, 200, 500) # Number of participant of normative Data
noise_values = c(1, 3)
sample_demo_fun_values = c("sample.demo.cond", "sample.demo.unif")
Capitani_ver_values = c("v1", "v2")
Arcara_ver_values = c("v1", "v2", "v3", "v5")
## create lists of combinations before running the sscript (useful if it kills to restart)
loop_list = list(NULL)
length(loop_list) = length(sample_size_values)*length(noise_values)*length(Capitani_ver_values)*length(Arcara_ver_values)*length(sample_demo_fun_values)
loop_list
### MAIN SCRIPT
# this script regulates the main values used for the simulation the article
# Arcara G. (2023) Improving ES.
rm(list=ls())
# the possible values of number of subjects on which normative data are built
sample_size_values = c(100, 200, 500) # Number of participant of normative Data
noise_values = c(1, 3)
sample_demo_fun_values = c("sample.demo.cond", "sample.demo.unif")
Capitani_ver_values = c("v1", "v2")
Arcara_ver_values = c("v1", "v2", "v3", "v5")
## create lists of combinations before running the sscript (useful if it kills to restart)
loop_list = list(NULL)
length(loop_list) = length(sample_size_values)*length(noise_values)*length(Capitani_ver_values)*length(Arcara_ver_values)*length(sample_demo_fun_values)
k = 1
### Create loop list
for (sample_size in sample_size_values){
for (noise_level in noise_values){
for (Arcara_ver in Arcara_ver_values){
for (Capitani_ver in Capitani_ver_values){
for (sample_demo_fun in sample_demo_fun_values){
loop_list[[k]] = list(sample_size = sample_size, noise_level=noise_level,
Arcara_ver=Arcara_ver, Capitani_ver=Capitani_ver, sample_demo_fun=sample_demo_fun)
print(k)
k=k+1
}
}
}
}
}
loop_list
loop_list[[1]]
loop_list[[2]]
loop_list[[3]]
loop_list[[1]]
loop_list[[2]]
loop_list[[3]]
### MAIN SCRIPT
# this script regulates the main values used for the simulation the article
# Arcara G. (2023) Improving ES.
rm(list=ls())
# the possible values of number of subjects on which normative data are built
sample_size_values = c(100, 200, 500) # Number of participant of normative Data
noise_values = c(1, 3)
sample_demo_fun_values = c("sample.demo.cond", "sample.demo.unif")
Capitani_ver_values = c("v1", "v2")
Arcara_ver_values = c("v1", "v2", "v3", "v5")
## create lists of combinations before running the sscript (useful if it kills to restart)
loop_list = list(NULL)
length(loop_list) = length(sample_size_values)*length(noise_values)*length(Capitani_ver_values)*length(Arcara_ver_values)*length(sample_demo_fun_values)
k = 1
### Create loop list
for (sample_size in sample_size_values){
for (noise_level in noise_values){
for (Arcara_ver in Arcara_ver_values){
for (Capitani_ver in Capitani_ver_values){
for (sample_demo_fun in sample_demo_fun_values){
loop_list[[k]] = list(sample_size = sample_size, noise_level=noise_level,
Arcara_ver=Arcara_ver, Capitani_ver=Capitani_ver, sample_demo_fun=sample_demo_fun)
print(k)
k=k+1
}
}
}
}
}
n_start=62
for (iLoop in n_start:length(loop_list)){
curr_loop = loop_list[[iLoop]]
assign("n.subj.train", curr_loop$sample_size, env=.BaseNamespaceEnv)
assign("True_score.mult", curr_loop$noise_level, env=.BaseNamespaceEnv)
assign("sample.demo.fun", curr_loop$sample_demo_fun, env=.BaseNamespaceEnv )
assign("Arcara_ver", curr_loop$Arcara_ver, env=.BaseNamespaceEnv)
assign("Capitani_ver", curr_loop$Capitani_ver, env=.BaseNamespaceEnv)
print(iLoop)
source("R_scripts/STEP2_simulation_fake.R", local=FALSE, verbose = F)
}
